{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp/qus/eK1W3JqK2vCCHUQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnpeniel01/hello-world/blob/master/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tay6gYuOWKl2",
        "outputId": "dec3ef7b-5789-4086-b599-7d8d68b19421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mRows: \u001b[22m\u001b[34m651191\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m2\u001b[39m\n",
            "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
            "\u001b[1mDelimiter:\u001b[22m \",\"\n",
            "\u001b[31mchr\u001b[39m (2): url, type\n",
            "\n",
            "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
            "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "library(readr)\n",
        "Dataset <- read_csv(\"Dataset.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(dplyr)\n",
        "\n",
        "# Stratified sampling using dplyr\n",
        "sampled_data <- Dataset %>%\n",
        "  group_by(Dataset$type) %>%\n",
        "  sample_frac(0.05)\n",
        "View(sampled_data)\n",
        "summary(sampled_data)"
      ],
      "metadata": {
        "id": "i-7StxlKXK7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "library(stringr)\n",
        "# Creating a variable called \"url_len\" to store the length of the URL\n",
        "Dataset$url_len <- nchar(Dataset$url)\n",
        "\n",
        "\n",
        "\n",
        "# the number of digits in the URL\n",
        "Dataset$n_num <-  nchar(gsub(\"[^0-9]+\", \"\", Dataset$url))\n",
        "\n",
        "\n",
        "# Count the number of special characters in URL\n",
        "Dataset$n_xtr <- str_count( Dataset$url,\"[^a-zA-Z0-9]\")\n",
        "\n",
        "\n",
        "# Count number of Alphabets in URLs\n",
        "count_alphabets <- function(url) {\n",
        "  # Use gsub to remove non-alphabetic characters\n",
        "  alpha_only <- gsub(\"[^a-zA-Z]\", \"\", url)\n",
        "\n",
        "  # Count the number of alphabets\n",
        "  num_alphabets <- nchar(alpha_only)\n",
        "\n",
        "  return(num_alphabets)\n",
        "}\n",
        "\n",
        "\n",
        "Dataset$n_alpha <- sapply(Dataset$url, count_alphabets)\n",
        "\n",
        "\n",
        "# Count lowercase letters in  URLs\n",
        "count_lowercase <- function(url) {\n",
        "  # Use gsub to remove non-lowercase letters\n",
        "  lowercase_only <- gsub(\"[^a-z]\", \"\", url)\n",
        "\n",
        "  # Count the number of lowercase letters\n",
        "  num_lowercase <- nchar(lowercase_only)\n",
        "\n",
        "  return(num_lowercase)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$n_lowcase <- sapply(Dataset$url, count_lowercase)\n",
        "\n",
        "\n",
        "# Count uppercase letters in URLs\n",
        "count_uppercase <- function(url) {\n",
        "  # Use gsub to remove non-lowercase letters\n",
        "  uppercase_only <- gsub(\"[^A-Z]\", \"\", url)\n",
        "\n",
        "  # Count the number of lowercase letters\n",
        "  num_uppercase <- nchar(uppercase_only)\n",
        "\n",
        "  return(num_uppercase)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$n_upcase <- sapply(Dataset$url, count_uppercase)\n",
        "\n",
        "\n",
        "#Occurrences of \"http\" in a URL\n",
        "countHttpOccurrences <- function(url) {\n",
        "  httpCount <- sum(grepl(\"http\", url))\n",
        "  return(httpCount)\n",
        "}\n",
        "\n",
        "# Apply the function to the 'url' column in the data frame\n",
        "Dataset$n_http <- sapply(Dataset$url, countHttpOccurrences)\n",
        "\n",
        "\n",
        "\n",
        "# Occurrences of \"https\" in a URL\n",
        "countHttspOccurrences <- function(url) {\n",
        "  httpsCount <- sum(grepl(\"https\", url))\n",
        "  return(httpsCount)\n",
        "}\n",
        "\n",
        "# Apply the function to the 'url' column in the data frame\n",
        "Dataset$n_https <- sapply(Dataset$url, countHttspOccurrences)\n",
        "\n",
        "\n",
        "# Count '@' symbols in  URLs\n",
        "count_at_symbols <- function(url) {\n",
        "  return(sum(str_count(url, \"@\")))\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$num_at <- sapply(Dataset$url, count_at_symbols)\n",
        "\n",
        "\n",
        "\n",
        "# Check the presence of an IP address in URLs\n",
        "has_ip <- function(url) {\n",
        "  # Regular expression to match IPv4 addresses\n",
        "  ip_pattern <- \"\\\\b(?:\\\\d{1,3}\\\\.){3}\\\\d{1,3}\\\\b\"\n",
        "\n",
        "  # Use grepl to check if the URL contains an IP address\n",
        "  has_ip <- grepl(ip_pattern, url)\n",
        "\n",
        "  return(as.numeric(has_ip))\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$has_ip <- sapply(Dataset$url, has_ip)\n",
        "\n",
        "\n",
        "# Count '&' symbols in URLs\n",
        "count_and_symbols <- function(url) {\n",
        "  return(sum(str_count(url, \"&\")))\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$n_and <- sapply(Dataset$url, count_and_symbols)\n",
        "\n",
        "\n",
        "# Count ';' symbols in URLs\n",
        "count_semi_symbols <- function(url) {\n",
        "  return(sum(str_count(url, \";\")))\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$n_semi <- sapply(Dataset$url, count_semi_symbols)\n",
        "\n",
        "\n",
        "\n",
        "# Count '//' symbols in URLs\n",
        "count_doubleSlash_symbols <- function(url) {\n",
        "  return(sum(str_count(url, \"//\")))\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$n_dbSlash <- sapply(Dataset$url, count_doubleSlash_symbols)\n",
        "\n",
        "\n",
        "#Count number of Dots \".\" in domain\n",
        "countdotInDomain <- function(url) {\n",
        "  # Extract the domain part from the URL\n",
        "  domain <- sub(\"^https?://([^/]+).*\", \"\\\\1\", url)\n",
        "  dotCount <- sum(strsplit(domain, \"\")[[1]] == \".\")\n",
        "  return(dotCount)\n",
        "}\n",
        "\n",
        "# Apply the function to the 'url' column in the data frame\n",
        "Dataset$n_dot_domain <- sapply(Dataset$url, countdotInDomain)\n",
        "\n",
        "\n",
        "#Count number of Hyphens \"-\" in domain\n",
        "counthyphenInDomain <- function(url) {\n",
        "  # Extract the domain part from the URL\n",
        "  domain <- sub(\"^https?://([^/]+).*\", \"\\\\1\", url)\n",
        "  hyphenCount <- sum(strsplit(domain, \"\")[[1]] == \"-\")\n",
        "  return(hyphenCount)\n",
        "}\n",
        "\n",
        "# Apply the function to the 'url' column in the data frame\n",
        "Dataset$n_hyphen_domain <- sapply(Dataset$url, counthyphenInDomain)\n",
        "\n",
        "\n",
        "# Count the length of the domain in URLs\n",
        "count_domain_length <- function(url) {\n",
        "  # Use regex to extract the domain\n",
        "  domain <- sub(\"https?://([^/]+).*\", \"\\\\1\", url)\n",
        "\n",
        "  # Count the length of the domain\n",
        "  domain_length <- nchar(domain)\n",
        "\n",
        "  return(domain_length)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$domain_length <- sapply(Dataset$url, count_domain_length)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the ratio of numbers in URLs\n",
        "calculate_number_ratio <- function(url) {\n",
        "  # Extract only the numbers from the URL\n",
        "  numbers <- gsub(\"[^0-9]\", \"\", url)\n",
        "\n",
        "  # Calculate the ratio of numbers to the total number of characters\n",
        "  ratio <- nchar(numbers) / nchar(url)\n",
        "\n",
        "  return(ratio)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$num_ratio <- sapply(Dataset$url, calculate_number_ratio)\n",
        "\n",
        "\n",
        "# Calculate the ratio of alphabets in URLs\n",
        "calculate_alphabet_ratio <- function(url) {\n",
        "  # Extract only the alphabets from the URL\n",
        "  alphabets <- gsub(\"[^a-zA-Z]\", \"\", url)\n",
        "\n",
        "  # Calculate the ratio of alphabets to the total number of characters\n",
        "  ratio <- nchar(alphabets) / nchar(url)\n",
        "\n",
        "  return(ratio)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$alpha_ratio <- sapply(Dataset$url, calculate_alphabet_ratio)\n",
        "\n",
        "\n",
        "# Calculate the ratio of lowercase letters in URLs\n",
        "calculate_lowercase_ratio <- function(url) {\n",
        "  # Extract only the lowercase letters from the URL\n",
        "  lowercase_letters <- gsub(\"[^a-z]\", \"\", url)\n",
        "\n",
        "  # Calculate the ratio of lowercase letters to the total number of characters\n",
        "  ratio <- nchar(lowercase_letters) / nchar(url)\n",
        "\n",
        "  return(ratio)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$lwcase_ratio <- sapply(Dataset$url, calculate_lowercase_ratio)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the ratio of uppercase letters in a URL\n",
        "calculate_uppercase_ratio <- function(url) {\n",
        "  # Extract only the uppercase letters from the URL\n",
        "  uppercase_letters <- gsub(\"[^A-Z]\", \"\", url)\n",
        "\n",
        "  # Calculate the ratio of uppercase letters to the total number of characters\n",
        "  ratio <- nchar(uppercase_letters) / nchar(url)\n",
        "\n",
        "  return(ratio)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$up_ratio <- sapply(Dataset$url, calculate_uppercase_ratio)\n",
        "\n",
        "\n",
        "# Calculate the ratio of special characters in a URL\n",
        "calculate_special_char_ratio <- function(url) {\n",
        "  # Extract only the special characters from the URL\n",
        "  special_chars <- gsub(\"[a-zA-Z0-9]\", \"\", url)\n",
        "\n",
        "  # Calculate the ratio of special characters to the total number of characters\n",
        "  ratio <- nchar(special_chars) / nchar(url)\n",
        "\n",
        "  return(ratio)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$sp_char_ratio <- sapply(Dataset$url, calculate_special_char_ratio)\n",
        "\n",
        "\n",
        "\n",
        "#Count English words in URLs\n",
        "count_english_words <- function(url) {\n",
        "  # Extract consecutive sequences of alphabetic characters as words\n",
        "  words <- strsplit(gsub(\"[^a-zA-Z]+\", \" \", url), \" \")[[1]]\n",
        "\n",
        "  # Count the number of words\n",
        "  num_words <- length(words)\n",
        "\n",
        "  return(num_words)\n",
        "}\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$n_eng_words <- sapply(Dataset$url, count_english_words)\n",
        "\n",
        "\n",
        "\n",
        "# Count random words in URLs\n",
        "count_random_words <- function(url) {\n",
        "  # Extract consecutive sequences of non-alphabetic characters as random words\n",
        "  random_words <- strsplit(gsub(\"[a-zA-Z]+\", \" \", url), \" \")[[1]]\n",
        "\n",
        "  # Remove empty strings\n",
        "  random_words <- random_words[random_words != \"\"]\n",
        "\n",
        "  # Count the number of random words\n",
        "  num_random_words <- length(random_words)\n",
        "\n",
        "  return(num_random_words)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$n_rd_words <- sapply(Dataset$url, count_random_words)\n",
        "\n",
        "\n",
        "# Calculate the average English word length in URLs\n",
        "calculate_avg_word_length <- function(url) {\n",
        "  # Extract consecutive sequences of alphabetic characters as words\n",
        "  words <- strsplit(gsub(\"[^a-zA-Z]+\", \" \", url), \" \")[[1]]\n",
        "\n",
        "  # Remove empty strings\n",
        "  words <- words[words != \"\"]\n",
        "\n",
        "  # Calculate the average word length, replacing NaN with 0\n",
        "  avg_word_length <- ifelse(length(words) > 0, mean(nchar(words)), 0)\n",
        "\n",
        "  return(avg_word_length)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$avg_wd_len <- sapply(Dataset$url, calculate_avg_word_length)\n",
        "\n",
        "\n",
        "# Function to calculate the average length of random words in a URL\n",
        "calculate_avg_random_word_length <- function(url) {\n",
        "  # Extract consecutive sequences of non-alphabetic characters as random words\n",
        "  random_words <- strsplit(gsub(\"[a-zA-Z]+\", \" \", url), \" \")[[1]]\n",
        "\n",
        "  # Remove empty strings\n",
        "  random_words <- random_words[random_words != \"\"]\n",
        "\n",
        "  avg_random_word_length <- ifelse(length(random_words) > 0, mean(nchar(random_words)), 0)\n",
        "\n",
        "\n",
        "\n",
        "  return(avg_random_word_length)\n",
        "}\n",
        "\n",
        "# Apply the function to each URL in the dataset\n",
        "Dataset$avg_rd_wd_len <- sapply(Dataset$url, calculate_avg_random_word_length)\n"
      ],
      "metadata": {
        "id": "qttv0YDuXsn9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset <- sampled_data[,-1]\n",
        "\n",
        "\n",
        "dataset$type <- as.character(dataset$type)\n"
      ],
      "metadata": {
        "id": "u7rk0zYhcLNB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset$type <- as.character(dataset$type)"
      ],
      "metadata": {
        "id": "OmOBHFDFh3aL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install.packages(\"caret\")\n",
        "library(caret)\n",
        "validation_index <- createDataPartition(dataset$type, p=0.80, list = FALSE)\n",
        "validation <- dataset[-validation_index,]\n",
        "trainset <- dataset[validation_index,]"
      ],
      "metadata": {
        "id": "gOI9pZRqcams"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"randomForest\")"
      ],
      "metadata": {
        "id": "EV_OW-cme08R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "levels(dataset$type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "m6lGJ2hFhMNL",
        "outputId": "87297ab1-c8d6-44a0-df43-0ae82e6bea08"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NULL"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "GoRA1GWShXyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train with Random Forest\n",
        "library(randomForest)\n",
        "model<- randomForest(type~., data = dataset, ntree=500, mtry=5, importance=TRUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "CboykPehepGE",
        "outputId": "780d7fd0-730a-4aaa-ef77-42782380d4fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in eval(predvars, data, env): object 'Dataset$type' not found\nTraceback:\n",
            "1. randomForest(type ~ ., data = dataset, ntree = 500, mtry = 5, \n .     importance = TRUE)",
            "2. randomForest.formula(type ~ ., data = dataset, ntree = 500, mtry = 5, \n .     importance = TRUE)",
            "3. model.frame(terms(reformulate(attributes(Terms)$term.labels)), \n .     data.frame(m))",
            "4. model.frame.default(terms(reformulate(attributes(Terms)$term.labels)), \n .     data.frame(m))",
            "5. eval(predvars, data, env)",
            "6. eval(predvars, data, env)"
          ]
        }
      ]
    }
  ]
}